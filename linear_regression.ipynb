{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Linear Regression\n",
    "\n",
    "_Authors: Kevin Markham (Washington, D.C.), Ed Podojil (New York City)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Objectives\n",
    "- Define data modeling and simple linear regression.\n",
    "- Build a linear regression model using a data set that meets the linearity assumption using the scikit-learn library.\n",
    "- Understand and identify multicollinearity in a multiple regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduce-the-bikeshare-dataset\"></a>\n",
    "## Introduce the Bikeshare Data Set\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use bikeshare data to build a simple demand forecasting model.\n",
    "\n",
    "**Possible applications:**\n",
    "\n",
    "* Find where to site new bikeshare stations and know how large of a station to build.\n",
    "* Calculate the expected wear and tear on bikes and what the replacement costs will be.\n",
    "* Use a slightly different research design to forecast full and empty stations and send a service vehicle to \"rebalance\" the bikes from one station to another, as sometimes bikeshare stations have no bikes or are completely full and prevent use of the station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"read-in-the--capital-bikeshare-data\"></a>\n",
    "### Read In the Capital Bikeshare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data and set the datetime as the index.\n",
    "url = './data/bikeshare.csv'\n",
    "bikes = pd.read_csv(url, index_col='datetime', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preview the first five rows of the DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does each observation (row) represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`num_total_users` indicates the total number of riders. It will be the target variable that we try to forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many features are there?\n",
    "\n",
    "Don't num_total_users \"num_casual_users\" or \"num_registered_users\" -- they are segments of the total users, so they are alternative target variables  that aren't available for forecasting total users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable| Description |\n",
    "|---------|----------------|\n",
    "|datetime| hourly date + timestamp  |\n",
    "|season|  1 = spring, 2 = summer, 3 = fall, 4 = winter |\n",
    "|holiday| whether the day is considered a holiday|\n",
    "|workingday| whether the day is neither a weekend nor holiday|\n",
    "|weather| 1: Clear, 2: Mist, 3: Light Rain or Snow 4: Heavy Rain or Snow|\n",
    "|temp| temp_celsius in Celsius|\n",
    "|atemp| \"feels like\" temp_celsius in Celsius|\n",
    "|humidity| relative humidity|\n",
    "|windspeed| wind speed|\n",
    "|casual| number of non-num_registered_users user rentals initiated|\n",
    "|registered| number of num_registered_users user rentals initiated|\n",
    "|count| number of total rentals|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "Rename the columns in `bikes` as indicated below.\n",
    "\n",
    "| old name | new name |\n",
    "| ---    | --- |\n",
    "| temp | temp_celsius\n",
    "| windspeed | windspeed_knots\n",
    "| casual | num_casual_users\n",
    "| registered | num_registered_users\n",
    "| season | season_num\n",
    "| holiday | is_holiday\n",
    "| workingday | is_workingday\n",
    "| humidity | humidity_percent\n",
    "| count | num_total_users\n",
    "\n",
    "Using these more explicit names will make it easier to avoid mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualizing-the-data\"></a>\n",
    "### Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pandas scatterplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seaborn scatterplot with regression line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just created a linear regression model!\n",
    "\n",
    "- **Formula for a line:** $y = mx + b$\n",
    "- **Our model:** $\\mbox{num_total_users} = \\alpha * \\mbox{temp_celsius} + \\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call $\\alpha$ the **coefficient** of `temp_celsius` and $\\beta$ the **model intercept**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Answer each question with an expression that includes one or more symbols, rather than an exact number. The symbol $\\alpha$ is called \"alpha,\" and the symbol $\\beta$ is called \"beta.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What would our model predict for `num_total_users` at `temp_celsius=0`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If `temp_celsius` increases by 5, how does our model's prediction for `num_total_users` change? What if $\\alpha$ were negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I claim that this model does *not* tell us how the number of total uses would change if we were (somehow) to intervene to increase $temp\\_celsius$ by 5. Why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with one input feature chooses the *line* that \"best fits\" a scatterplot of the target variable against that input feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Linear Regression Models with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn is the most popular Python library for machine learning.\n",
    "\n",
    "**Strengths:**\n",
    "\n",
    "- Includes good implementations of a wide range of algorithms.\n",
    "- Interface is consistent across model types.\n",
    "- Documentation is excellent.\n",
    "- Large community --> tons of resources for learning and getting questions answered.\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "- Deep learning capabilites are very basic.\n",
    "- Reflects machine learning rather than statistics mindset: focuses on predictive accuracy on held-out data rather than hypothesis testing, parameter estimation, and model interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the LinearRegression model class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make an instance of the LinearRegression class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model instance on our data, using just temp_celsius for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the fitted values to our DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare fitted values to actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the fitted values from our DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scikit-learns--step-modeling-pattern\"></a>\n",
    "### scikit-learn's Four-Step Modeling Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the class you plan to use.\n",
    "2. \"Instantiate\" the class. You can specify \"hyperparameters\" at this point.\n",
    "3. Fit the model instance with data. (This step changes the model object in-place.)\n",
    "4. Use the fitted model to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build another linear regression model, this time using all of our features as inputs instead of just `temp_celsius`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Store a pandas DataFrame with the values of the feature variables (everything except `num_casual_users`, and `num_total_users`) as a Python variable X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run the cell below to check your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tests\n",
    "assert isinstance(y, pd.Series)\n",
    "assert isinstance(X, pd.DataFrame)\n",
    "assert y.shape[0] == bikes.shape[0]\n",
    "assert X.shape == (bikes.shape[0], bikes.shape[1] - 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make a new instance of the LinearRegression class. Call it lr_all to distinguish it from our last model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the model instance using our new feature matrix $X$ and the same target variable $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Store `lr_all`'s fitted values in a new `predictions` column of the `bikes` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare predicted values to actual\n",
    "fig, ax = plt.subplots()\n",
    "bikes.plot(kind='scatter', x='num_total_users', y='predictions', ax=ax)\n",
    "ax.plot([0, 500], [0, 500], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the fitted values from our DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows how well the model fits the data it was trained on. How well it would predict new data that it wasn't trained on is a further issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Multiple Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Our first model:**\n",
    "    - **$y=mx+b$ notation:**\n",
    "       - $\\mbox{num_total_users} = \\alpha * \\mbox{temp_celsius} + \\beta$\n",
    "    - **New notation:**\n",
    "       - $\\mbox{num_total_users} = \\beta_0 +  \\beta_1 * \\mbox{temp_celsius}$\n",
    "- **Our second model:**\n",
    "    - $\\mbox{num_total_users} = \\beta_0 + \\beta_1 * \\mbox{season_num} + \\beta_2 * \\mbox{is_holiday} + \\beta_3 * \\mbox{is_workingday} + \\beta_4 * \\mbox{weather} + \\beta_5 * \\mbox{temp_celsius} + \\beta_6 * \\mbox{atemp_celsius} + \\beta_7 * \\mbox{humidity_percent} + \\beta_8 * \\mbox{windspeed_knots}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Answer each question with an expression that includes one or more symbols, rather than an exact number. The symbol $\\beta$ is called \"beta.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What would our model predict for `num_total_users` at with all input features 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If `humidity_percent` decreases by 3 while all other features remain fixed, how does our model's prediction for `num_total_users` change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why does the previous question say \"while all other features remain fixed?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What would it mean if a feature had a coefficient of 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with two input features chooses the \"plane\" that \"best fits\" a 3D scatterplot of the target variable against those input features.\n",
    "\n",
    "In general, linear regression chooses the \"hyperplane\" that \"best fits\" a scatterplot of the target variable against the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the intercept and coefficients of the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** How do the model's predictions change for a holiday vs. a non-holiday, all else being equal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at the documentation for a LinearRegression model object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Little Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a linear regression selects the coefficients and intercept that minimize the **sum of squared errors** of the fitted values on the training set.\n",
    "\n",
    "![Estimating coefficients](./assets/estimating_coefficients.png)\n",
    "\n",
    "In the diagram above:\n",
    "\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the vertical distances between the observed values and the least squares line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justification:** Minimizing the sum of squared errors maximizes *the probability of the data given the model* (the **likelihood** of the model on the data) on the assumption that the target variable really is a linear function of the features plus normally distributed \"noise:\" $y = \\beta_0 + \\sum \\beta_i x_i + \\epsilon$ where $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$\n",
    "\n",
    "![](./assets/400px-Linear_regression.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** In our second model, does it appear that the target variable is a linear function of the features plus normally distributed noise? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview-of-supervised-learning\"></a>\n",
    "## Overview of Supervised Learning\n",
    "---\n",
    "\n",
    "![Supervised learning diagram](./assets/supervised_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"does-the-scale-of-the-features-matter\"></a>\n",
    "### Does the Scale of the Features Matter?\n",
    "\n",
    "Let's say that temp_celsius was measured in Fahrenheit, rather than Celsius. How would that affect our first model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new column for Fahrenheit temp_celsius.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seaborn scatterplot with regression line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebuild the first model using temp_fahrenheit instead or temp_celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert 25 degrees Celsius to Fahrenheit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "25*1.8 + 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict rentals for 25 degree celsius and for 77 degrees Fahrenheit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** The scale of the features is irrelevant for linear regression models. When changing the scale, we simply change our interpretation of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the temp_fahrenheit column.\n",
    "bikes.drop('temp_fahrenheit', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualizing-the-data-part-\"></a>\n",
    "### Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blindly throwing all of your variables into a linear regression model is not a great strategy. Let's inspect our data and come up with something smarter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore a few features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create feature column variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a subset of scatterplot matrix using Seaborn.\n",
    "We can use pairplot with the `y_vars` argument to only show relationships with the `num_total_users` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multiple scatterplots in Seaborn\n",
    "sns.pairplot(bikes,\n",
    "             x_vars=feature_cols,\n",
    "             y_vars='num_total_users',\n",
    "             kind='reg',\n",
    "             plot_kws={'scatter_kws': {'s':1, 'alpha':.3},\n",
    "                       'line_kws': {'color':'red'}\n",
    "                       }\n",
    "             );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/poll \"Which is the best interpretation of the slope of the line for `num_total_users` against `humidity_percent`?\" \"How much a linear regression model's predictions for `num_total_users` against `humidity_percent` would change given a one-unit change in `humidity_percent`\" \"How much a linear regression model's predictions for `num_total_users` against `temp_celsius`, `season_num`, `weather`, and `humidity_percent` would change given a one-unit change in `humidity_percent`\" \"How much a linear regression model's predictions for `num_total_users` against `temp_celsius`, `season_num`, `weather`, and `humidity_percent` would change given a one-unit change in `humidity_percent`, holding all of those other variables constant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the season_num variable using a cross-tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-tabulation of season_num and month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the season_num variable using a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Box plot of rentals, grouped by season_num.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at rentals over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Line plot of rentals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Trend:** System is generall growing over time.\n",
    "- **Seasonality:** Periodic patterns in the data:\n",
    "    - Yearly\n",
    "    - Weekly\n",
    "    - Daily\n",
    "\n",
    "A good model will account for both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize correlation matrix in Seaborn using a heat map.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "\n",
    "- We have two pairs of variables that are extremely strongly correlated. Which are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which features are positively correlated with `num_total_users` (leaving aside `num_casual users` and `num_registered_users`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which features are negatively correlated with `num_total_users` (leaving aside `num_casual users` and `num_registered_users`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which features show very little correlation with `num_total_users` (leaving aside `num_casual users` and `num_registered_users`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"adding-more-features-to-the-model\"></a>\n",
    "### Adding More Features to the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want features that are strongly correlated with the target and not with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "\n",
    "- Create another `LinearRegression` instance that is fit using `temp_celsius` and `atemp_celsius`, and print the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create another `LinearRegression` instance that is fit using `atemp_celsius` only, and print the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why is the coefficient for `atemp` so different in the two models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-multicollinearity\"></a>\n",
    "## What Is Colinearity?\n",
    "---\n",
    "\n",
    "Colinearity happens when two or more features are highly correlated with each other. It causes problems:\n",
    "\n",
    "- Coefficients become hard to interpret\n",
    "- Adding a variable to the model that is colinear with another variable in the model adds complexity while contributing limited new information, which can lead to overfitting.\n",
    "- Model fitting can become numerically unstable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Select a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall: Model Bias and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a LOT of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a model on the first 1000 rows and look at the fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See how the model does on the next 1000 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Moral 1:** Models that are too complicated for the sample size will fit the training data well but generalize poorly; this phenomenon is called **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "\n",
    "- Does this overly complicated model have more of a bias problem or more of a variance problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Moral 2:** If our primary concern is how well our model generalizes to new data, then we can evaluate it by seeing how it does on data that we hold out from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "- If you have a stats background then you might be used to using p-values to decide what variables to keep, or perhaps specialized model selection criteria such as adjusted R-squared, AIC, or BIC. But if what you really care about is predictive accuracy on data that the model hasn't seen before, then using a holdout set is much more direct.\n",
    "- In a business context, you may sacrifice some predictive accuracy by using fewer input features for the sake of maintainability and computational performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluation-metrics-for-regression-problems\"></a>\n",
    "### Evaluation Metrics for Regression Problems\n",
    "\n",
    "**Mean absolute error (MAE)** is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean squared error (MSE)** is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root mean squared error (RMSE)** is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Calculate MAE, MSE, and RMSE for the values below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example true and predicted response values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in these calculations. Hint: Turn the lists in numpy arrays.\n",
    "mae = None\n",
    "mse = None\n",
    "rmse = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to check your answers.\n",
    "\n",
    "from sklearn import metrics\n",
    "print(mae)\n",
    "print(mse)\n",
    "print(rmse)\n",
    "np.testing.assert_almost_equal(mae, metrics.mean_absolute_error(true, pred))\n",
    "np.testing.assert_almost_equal(mse, metrics.mean_squared_error(true, pred))\n",
    "np.testing.assert_almost_equal(rmse, np.sqrt(metrics.mean_squared_error(true, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare these metrics:\n",
    "\n",
    "- MAE is the easiest to understand, because it's the average error.\n",
    "- MSE is more popular than MAE, primary because the fact that it is continuous and differentiable makes it easier to work with.\n",
    "- RMSE is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "- MSE/MSE punishes large errors more than MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-models-with-traintest-split-and-rmse\"></a>\n",
    "### Comparing Models With Train/Test Split and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define a function that accepts a list of features and returns testing RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare different sets of features.\n",
    "print(train_test_rmse(bikes, ['temp_celsius', 'season_num', 'weather', 'humidity_percent']))\n",
    "print(train_test_rmse(bikes, ['temp_celsius', 'season_num', 'weather']))\n",
    "print(train_test_rmse(bikes, ['temp_celsius', 'season_num', 'humidity_percent']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using these as features is not allowed!\n",
    "print(train_test_rmse(bikes, ['num_casual_users', 'num_registered_users']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-testing-rmse-with-null-rmse\"></a>\n",
    "### Comparing Testing RMSE With Null RMSE\n",
    "\n",
    "Null RMSE is the RMSE that could be achieved by always predicting the mean response value. It is a baseline against which you may want to measure your regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"handling-categorical-features\"></a>\n",
    "## Handling Categorical and Ordinal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "\n",
    "We are representing `season` as follows:\n",
    "\n",
    "1: winter\n",
    "2: spring\n",
    "3: summer\n",
    "4: fall\n",
    "\n",
    "- Suppose we fit linear regression model for ridership against season only and get a coefficient 10 for `season`. What does this coefficient imply about the relationship between predicted ridership for fall relative to summer? How could we get this result even though ridership is higher in summer than fall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Coding\n",
    "\n",
    "Here's a better representation:\n",
    "\n",
    "- `is_spring`: 1 in spring, 0 otherwise\n",
    "- `is_summer`: 1 in summer, 0 otherwise\n",
    "- `is_fall`: 1 in fall, 0 otherwise\n",
    "\n",
    "Instead of having one variable with 4 levels, we have 3 binary variables.\n",
    "\n",
    "Our model now has three \"degrees of freedom\" to capture the impact of the season, instead of just one.\n",
    "\n",
    "This process is called \"dummy coding.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "1. Why is `is_winter` unnecessary?\n",
    "2. In fact, why would including `is_winter` be harmful?\n",
    "3. Suppose you build a model with these variables and find that the coefficient on `is_summer` is 30. What does that coefficient mean?\n",
    "4. Could you use `is_winter`, `is_spring`, and `is_summer` instead? Why or why not? Is there any reason to prefer one set of dummy variables over another?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy coding with pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop a redundant column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike `season`, our variable `weather` is at least ordinal:\n",
    "\n",
    "1: Clear, 2: Mist, 3: Light Rain or Snow 4: Heavy Rain or Snow\n",
    "\n",
    "However, there's no reason to assume that the difference between Clear and Mist has the same impact on ridership as the difference between Mist and List Rain/Snow or the difference between Light Rain/Snow and Heavy Rain/Snow. Here too our model can benefit from the additional degrees of freedom that dummy coding provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "\n",
    "- Use pandas to create dummy columns for `weather`, and drop the column that you want to use as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many dummy variables do you need for a categorical feature with $k$ possible values? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rerun the linear regression with dummy variables included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Include dummy variables for season_num in the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.**\n",
    "\n",
    "1. What does the coefficient for summer mean?\n",
    "2. Huh? How can we get a coefficient of -46.37 in summer, the most popular season?\n",
    "3. Would our model's predictions change if we dropped a different dummy column for season?\n",
    "4. Use train_test_rmse to compare the performance of a model with `temp_celsius`, `season_num`, and `humidity_percent` to one that replaces `season_num` with its dummies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"feature-engineering\"></a>\n",
    "### Feature Engineering Exercise\n",
    "\n",
    "See if you can create the following features:\n",
    "\n",
    "- **hour:** as a single numeric feature (0 through 23)\n",
    "- **hour:** as a categorical feature (use 23 dummy variables)\n",
    "- **daytime:** as a single categorical feature (daytime=1 from 7 a.m. to 8 p.m., and daytime=0 otherwise)\n",
    "\n",
    "Then, try using each of the three features (on its own) with `train_test_rmse` to see which one performs the best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract hour of the day to use as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode `hour` as a categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a `daytime` variable based on hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the root mean squared error of our various `hour` encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bonus-material-regularization\"></a>\n",
    "## Bonus Material: Regularization\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overly complicated models don't generalize well.\n",
    "- One way to reduce model complexity is to use fewer features.\n",
    "- Another way is to incorporate a penalty for coefficient size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"how-does-regularization-work\"></a>\n",
    "### How Does Regularization Work?\n",
    "\n",
    "For a normal linear regression model, we estimate the coefficients using the least squares criterion, which minimizes the residual sum of squares (RSS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a regularized linear regression model, we minimize the sum of MSE and a \"penalty term\" that penalizes coefficient size.\n",
    "\n",
    "**Ridge regression** (or \"L2 regularization\") minimizes: $$\\mbox{MSE} + \\alpha \\sum_{j=1}^p \\beta_j^2$$\n",
    "\n",
    "**Lasso regression** (or \"L1 regularization\") minimizes: $$\\text{Mse} + \\alpha \\sum_{j=1}^p |\\beta_j|$$\n",
    "\n",
    "- $p$ is the number of features.\n",
    "- $\\beta_j$ is a model coefficient.\n",
    "- $\\alpha$ is a tuning parameter:\n",
    "    - A tiny $\\alpha$ imposes no penalty on the coefficient size, and is equivalent to a normal linear regression model.\n",
    "    - Increasing the $\\alpha$ penalizes the coefficients and thus shrinks them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lasso-and-ridge-path-diagrams\"></a>\n",
    "### Lasso and Ridge Path Diagrams\n",
    "\n",
    "A larger alpha (toward the left of each diagram) results in more regularization:\n",
    "\n",
    "- Lasso regression shrinks coefficients all the way to zero, thus removing them from the model.\n",
    "- Ridge regression shrinks coefficients toward zero, but they rarely reach zero.\n",
    "\n",
    "Source code for the diagrams: [Lasso regression](http://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_lars.html) and [Ridge regression](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ridge_path.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lasso and Ridge Coefficient Plots](./assets/lasso_ridge_path.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"advice-for-applying-regularization\"></a>\n",
    "### Advice for Applying Regularization\n",
    "\n",
    "**Standardize features (subtract mean and divide by standard deviation).**\n",
    "\n",
    "- Otherwise, features would be penalized simply because of their scale.\n",
    "- Avoids penalizing the intercept, which wouldn't make intuitive sense.\n",
    "\n",
    "**How should you choose between lasso regression and ridge regression?**\n",
    "\n",
    "- Lasso regression is preferred if we believe many features are irrelevant or if we prefer a sparse model.\n",
    "- Ridge can work particularly well if there is a high degree of multicollinearity in your model.\n",
    "- If model performance is your primary concern, it is best to try both.\n",
    "- Elastic net regression is a combination of lasso regression and ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ridge-regression\"></a>\n",
    "### Ridge Regression\n",
    "\n",
    "- [Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) documentation\n",
    "- **alpha:** must be positive, increase for more regularization\n",
    "- **normalize:** scales the features (without using StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Include dummy variables for season_num in the model.\n",
    "feature_cols = ['temp_celsius', 'atemp_celsius', 'spring', 'summer', 'fall', 'humidity_percent']\n",
    "X = bikes_dummies.loc[:, feature_cols]\n",
    "y = bikes_dummies.loc[:, 'num_total_users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alpha=0 is equivalent to linear regression.\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Instantiate the model.\n",
    "#(Alpha of zero has no regularization strength, essentially a basic linear regression.)\n",
    "ridgereg = Ridge(alpha=0, normalize=True)\n",
    "\n",
    "# Fit the model.\n",
    "ridgereg.fit(X_train, y_train)\n",
    "\n",
    "# Predict with fitted model.\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Coefficients for a non-regularized linear regression\n",
    "list(zip(feature_cols, ridgereg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret these coefficients we need to convert them back to original units, which is a reason to do normalization by hand. However, in this form the coefficients have a special meaning. The intercept is now the average of our outcome, and the magnitude of each coefficient in the model is a measure of how important it is in the model. We call this feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try alpha=0.1.\n",
    "ridgereg = Ridge(alpha=0.1, normalize=True)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Examine the coefficients.\n",
    "list(zip(feature_cols, ridgereg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-linear-regression-with-other-models\"></a>\n",
    "## Comparing Linear Regression With Other Models\n",
    "\n",
    "Advantages of linear regression:\n",
    "\n",
    "- Simple to explain.\n",
    "- Interpretable -- sort of.\n",
    "- Model training and prediction are fast.\n",
    "- No tuning is required (excluding regularization).\n",
    "- Features don't need scaling.\n",
    "- Can perform well with a small number of observations.\n",
    "- Well understood.\n",
    "\n",
    "Disadvantages of linear regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the response.\n",
    "- Performance is (generally) not competitive with the best supervised learning methods due to high bias.\n",
    "- Can't automatically learn feature interactions.\n",
    "- Easy to overinterpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Part 2 (Due Thurs., Feb. 22)\n",
    "https://git.generalassemb.ly/datr1618/final_project/blob/master/requirements.md#proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exit Tickets\n",
    "\n",
    "```\n",
    "=========================================\n",
    "@channel\n",
    "Exit Ticket: https://goo.gl/forms/OUw4gyTiRKMOTI3t2        \n",
    "\n",
    "#feedback\n",
    "=========================================\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
